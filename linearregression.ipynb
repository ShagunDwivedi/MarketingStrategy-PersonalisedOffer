{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-18T15:14:35.539302Z","iopub.execute_input":"2022-12-18T15:14:35.539681Z","iopub.status.idle":"2022-12-18T15:14:35.549096Z","shell.execute_reply.started":"2022-12-18T15:14:35.539649Z","shell.execute_reply":"2022-12-18T15:14:35.547811Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/marketing-strategy-personalised-offer/sample.csv\n/kaggle/input/marketing-strategy-personalised-offer/train_data.csv\n/kaggle/input/marketing-strategy-personalised-offer/test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, \\\n                                PolynomialFeatures, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.metrics import classification_report, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:14:35.550757Z","iopub.execute_input":"2022-12-18T15:14:35.551240Z","iopub.status.idle":"2022-12-18T15:14:36.551773Z","shell.execute_reply.started":"2022-12-18T15:14:35.551208Z","shell.execute_reply":"2022-12-18T15:14:36.550584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# test data\ntrue_data = pd.read_csv('../input/marketing-strategy-personalised-offer/test_data.csv')\n\n# train data raw\ntrain_data = pd.read_csv('../input/marketing-strategy-personalised-offer/train_data.csv')\n\ny_train_all = train_data.pop('Offer Accepted')","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:14:36.553895Z","iopub.execute_input":"2022-12-18T15:14:36.554317Z","iopub.status.idle":"2022-12-18T15:14:36.694261Z","shell.execute_reply.started":"2022-12-18T15:14:36.554289Z","shell.execute_reply":"2022-12-18T15:14:36.692604Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# replacing missing and unnecessary values \n\nall_col = [i for i in train_data.columns if i not in [\"car\",\"restuarant_opposite_direction_house\",\"travelled_more_than_5mins_for_offer\"]]\n\ntransformer1 = ColumnTransformer(\n    [\n        (\"drop_cols\", \"drop\", [\"car\",\"restuarant_opposite_direction_house\",\"travelled_more_than_5mins_for_offer\"]),\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\"), all_col)\n    ],\n    remainder=\"passthrough\"\n)\n\ntrain_data1 = pd.DataFrame(transformer1.fit_transform(train_data), columns=all_col)\ntrue_data1 = pd.DataFrame(transformer1.transform(true_data), columns=all_col)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:14:36.697762Z","iopub.execute_input":"2022-12-18T15:14:36.698122Z","iopub.status.idle":"2022-12-18T15:14:36.804366Z","shell.execute_reply.started":"2022-12-18T15:14:36.698084Z","shell.execute_reply":"2022-12-18T15:14:36.803284Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# column names\n\nno_enc = ['travelled_more_than_15mins_for_offer','Prefer western over chinese','travelled_more_than_25mins_for_offer',\n              'restuarant_same_direction_house','Cooks regularly','is foodie','has Children','Prefer home food','visit restaurant with rating (avg)']\nord_enc = ['offer expiration','income_range','no_visited_Cold drinks','no_visited_bars','no_Take-aways',\n           'Restaur_spend_less_than20','Restaur_spend_greater_than20', 'age','restaurant type','Qualification',\n          'Customer type','Marital Status','temperature','Travel Time']\n\n# ord_enc variables\n\nincome_list = np.array(['Less than ₹12500', '₹12500 - ₹24999', '₹25000 - ₹37499', \n               '₹37500 - ₹49999', '₹50000 - ₹62499', '₹62500 - ₹74999', \n                '₹75000 - ₹87499', '₹87500 - ₹99999',  '₹100000 or More'])\nno_list = np.array(['never', 'less1', '1~3', '4~8', 'gt8'])\noffer_list = np.array(['10hours', '2days'])\nage_list = np.array(['below21','21', '26', '31', '36', '41', '46','50plus'])\nresto_list = np.array(['Cold drinks','Take-away restaurant', 'Restaurant with pub',\n              '2 star restaurant','4 star restaurant'])\nquali_list = np.array(['Some High School','High School Graduate', 'Some college - no degree','Associates degree',\n              'Bachelors degree','Graduate degree (Masters or Doctorate)'])\ncusto_list = np.array(['Individual', 'With Colleagues', 'With Kids', 'With Family'])\nmarital_list = np.array([ 'Single', 'Unmarried partner','Married partner', 'Divorced', 'Widowed'])\ntemp_list = np.array([40, 67, 89])\ntravel_list = np.array([7, 10, 14, 18, 22])","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:14:50.237905Z","iopub.execute_input":"2022-12-18T15:14:50.238299Z","iopub.status.idle":"2022-12-18T15:14:50.248460Z","shell.execute_reply.started":"2022-12-18T15:14:50.238266Z","shell.execute_reply":"2022-12-18T15:14:50.247286Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ordinal encoding both test and training data\n\nincome_list_oe = OrdinalEncoder(categories=[income_list],dtype=np.int64)\nno_list_oe = OrdinalEncoder(categories=[no_list]*5,dtype=np.int64)\noffer_list_oe = OrdinalEncoder(categories=[offer_list],dtype=np.int64)\nage_list_oe = OrdinalEncoder(categories=[age_list],dtype=np.int64)\nresto_list_oe = OrdinalEncoder(categories=[resto_list],dtype=np.int64)\nquali_list_oe = OrdinalEncoder(categories=[quali_list],dtype=np.int64)\ncusto_list_oe = OrdinalEncoder(categories=[custo_list],dtype=np.int64)\nmarital_list_oe = OrdinalEncoder(categories=[marital_list],dtype=np.int64)\ntemp_list_oe = OrdinalEncoder(categories=[temp_list],dtype=np.int64)\ntravel_list_oe = OrdinalEncoder(categories=[travel_list],dtype=np.int64)\none_hot = OneHotEncoder(sparse=False,drop='first', dtype=np.int64)\n\ntransformer2 = ColumnTransformer(\n    [\n        ('offer_list_oe',offer_list_oe,['offer expiration']),\n        ('income_list_oe',income_list_oe,['income_range']),\n        ('no_list_oe',no_list_oe,['no_visited_Cold drinks','no_visited_bars','no_Take-aways','Restaur_spend_less_than20','Restaur_spend_greater_than20']),\n        ('age_list_oe',age_list_oe,['age']),\n        ('resto_list_oe',resto_list_oe,['restaurant type']),\n        ('quali_list_oe', quali_list_oe,['Qualification']),\n        ('custo_list_oe',custo_list_oe,['Customer type']),\n        ('marital_list_oe',marital_list_oe,['Marital Status']),\n        ('temp_list_oe',temp_list_oe,['temperature']),\n        ('travel_list_oe',travel_list_oe,['Travel Time'])\n    ],\n    remainder=\"drop\"\n)\n\nord_enc_data = pd.DataFrame(transformer2.fit_transform(train_data1), columns=ord_enc)\ntrue_ord_enc_data = pd.DataFrame(transformer2.fit_transform(true_data1), columns=ord_enc)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:15:08.909010Z","iopub.execute_input":"2022-12-18T15:15:08.909448Z","iopub.status.idle":"2022-12-18T15:15:09.015231Z","shell.execute_reply.started":"2022-12-18T15:15:08.909413Z","shell.execute_reply":"2022-12-18T15:15:09.013739Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# OneHotEncoding both test and train_data\n\ntransformer3 = ColumnTransformer(\n    [\n        ('one_hot1',one_hot,['Job/Job Industry']),\n        ('one_hot2',one_hot,['Climate']),\n        ('one_hot3',one_hot,['drop location']),\n        ('one_hot4',one_hot,['gender'])\n    ],\n    remainder=\"drop\"\n)\n\none_hot_data = pd.DataFrame(transformer3.fit_transform(train_data1), columns=[name.split(\"__\")[1] for name in transformer3.get_feature_names_out()])\none_hot_list = [name.split(\"__\")[1] for name in transformer3.get_feature_names_out()]\ntrue_one_hot_data = pd.DataFrame(transformer3.transform(true_data1), columns=one_hot_list)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:15:21.836312Z","iopub.execute_input":"2022-12-18T15:15:21.836766Z","iopub.status.idle":"2022-12-18T15:15:21.888417Z","shell.execute_reply.started":"2022-12-18T15:15:21.836729Z","shell.execute_reply":"2022-12-18T15:15:21.887184Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ss = StandardScaler()\n# final full training data\n\nX_train_full = train_data1[no_enc].astype('int64')\nX_train_full[one_hot_list] = one_hot_data\nX_train_full[ord_enc] = ord_enc_data\nX_train_full = pd.DataFrame(ss.fit_transform(X_train_full), columns=X_train_full.columns)\n\n# final full test data\n\nX_true = true_data1[no_enc].astype('int64')\nX_true[one_hot_list] = true_one_hot_data\nX_true[ord_enc] = true_ord_enc_data\nX_true = pd.DataFrame(ss.transform(X_true), columns=X_true.columns)\n\n# final full label\n\nle = LabelEncoder()\ny_train_full = le.fit_transform(y_train_all)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:15:42.169075Z","iopub.execute_input":"2022-12-18T15:15:42.169568Z","iopub.status.idle":"2022-12-18T15:15:42.240167Z","shell.execute_reply.started":"2022-12-18T15:15:42.169502Z","shell.execute_reply":"2022-12-18T15:15:42.239177Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=32)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:15:55.789054Z","iopub.execute_input":"2022-12-18T15:15:55.789417Z","iopub.status.idle":"2022-12-18T15:15:55.804709Z","shell.execute_reply.started":"2022-12-18T15:15:55.789385Z","shell.execute_reply":"2022-12-18T15:15:55.803384Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"# Logisitc Regression, Lasso\n\nmodel = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=32, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\nmodel.fit(X_train, y_train)\nprint(classification_report(y_test, model.predict(X_test)))\nprint(f1_score(y_test, model.predict(X_test), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:16:23.218343Z","iopub.execute_input":"2022-12-18T15:16:23.218701Z","iopub.status.idle":"2022-12-18T15:16:23.266959Z","shell.execute_reply.started":"2022-12-18T15:16:23.218675Z","shell.execute_reply":"2022-12-18T15:16:23.266160Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.54      0.33      0.41      1327\n           1       0.61      0.79      0.69      1768\n\n    accuracy                           0.59      3095\n   macro avg       0.58      0.56      0.55      3095\nweighted avg       0.58      0.59      0.57      3095\n\n0.5919224555735056\n","output_type":"stream"}]},{"cell_type":"code","source":"# Logisitc Regression, Ridge\n\nmodel = SGDClassifier(random_state=32, loss=\"log\", penalty=\"l2\")\nmodel.fit(X_train, y_train)\nprint(classification_report(y_test, model.predict(X_test)))\nprint(f1_score(y_test, model.predict(X_test), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:16:49.697889Z","iopub.execute_input":"2022-12-18T15:16:49.698295Z","iopub.status.idle":"2022-12-18T15:16:49.931809Z","shell.execute_reply.started":"2022-12-18T15:16:49.698264Z","shell.execute_reply":"2022-12-18T15:16:49.930993Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.50      0.43      0.46      1327\n           1       0.61      0.67      0.64      1768\n\n    accuracy                           0.57      3095\n   macro avg       0.55      0.55      0.55      3095\nweighted avg       0.56      0.57      0.56      3095\n\n0.5676898222940227\n","output_type":"stream"}]},{"cell_type":"code","source":"# Logisitc Regression, Elasticnet\n\nmodel = SGDClassifier(random_state=32, loss=\"log\", penalty=\"elasticnet\")\nmodel.fit(X_train, y_train)\nprint(classification_report(y_test, model.predict(X_test)))\nprint(f1_score(y_test, model.predict(X_test), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:17:20.778196Z","iopub.execute_input":"2022-12-18T15:17:20.778574Z","iopub.status.idle":"2022-12-18T15:17:21.168953Z","shell.execute_reply.started":"2022-12-18T15:17:20.778544Z","shell.execute_reply":"2022-12-18T15:17:21.167828Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.44      0.31      0.36      1327\n           1       0.58      0.70      0.63      1768\n\n    accuracy                           0.54      3095\n   macro avg       0.51      0.51      0.50      3095\nweighted avg       0.52      0.54      0.52      3095\n\n0.5353796445880452\n","output_type":"stream"}]},{"cell_type":"code","source":"# Perceptron Regression, Lasso\n\nmodel = SGDClassifier(random_state=32, loss=\"perceptron\", penalty=\"l1\")\nmodel.fit(X_train, y_train)\nprint(classification_report(y_test, model.predict(X_test)))\nprint(f1_score(y_test, model.predict(X_test), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:17:42.748757Z","iopub.execute_input":"2022-12-18T15:17:42.749110Z","iopub.status.idle":"2022-12-18T15:17:43.012297Z","shell.execute_reply.started":"2022-12-18T15:17:42.749079Z","shell.execute_reply":"2022-12-18T15:17:43.011428Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.45      0.68      0.54      1327\n           1       0.61      0.39      0.47      1768\n\n    accuracy                           0.51      3095\n   macro avg       0.53      0.53      0.51      3095\nweighted avg       0.54      0.51      0.50      3095\n\n0.5101777059773829\n","output_type":"stream"}]},{"cell_type":"code","source":"# Polynomial features (degree=2, including interaction) + Logistic Regression + Elasticnet\n\npolyn = PolynomialFeatures(2)\n\ntrain_data_poly = polyn.fit_transform(X_train_full)\nfeature_names = [i for i in polyn.get_feature_names_out()]\ntrain_df_poly = pd.DataFrame(data=train_data_poly, columns=feature_names)\n\nX_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(train_df_poly, y_train_full, test_size=0.3, random_state=32)\n\nmodel = SGDClassifier(random_state=32, loss=\"log\", penalty=\"elasticnet\")\nmodel.fit(X_train_poly, y_train_poly)\npreds = model.predict(X_test_poly)\nprint(classification_report(y_test_poly, preds))\nprint(f1_score(y_test_poly, model.predict(X_test_poly), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:18:31.539330Z","iopub.execute_input":"2022-12-18T15:18:31.540928Z","iopub.status.idle":"2022-12-18T15:18:49.212560Z","shell.execute_reply.started":"2022-12-18T15:18:31.540867Z","shell.execute_reply":"2022-12-18T15:18:49.211419Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.49      0.49      0.49      1597\n           1       0.61      0.61      0.61      2117\n\n    accuracy                           0.56      3714\n   macro avg       0.55      0.55      0.55      3714\nweighted avg       0.56      0.56      0.56      3714\n\n0.5592353257942919\n","output_type":"stream"}]},{"cell_type":"code","source":"# Logistic Regression hyper-parameter tuning\n\nparam_grid = {\n    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n    \"learning_rate\": [\"optimal\", \"invscaling\", \"adaptive\"],\n    \"eta0\": [1, 10, 100],\n    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"]\n}\nmodel = SGDClassifier(random_state=32, loss=\"log\")\nsearch = GridSearchCV(model, param_grid=param_grid, scoring=\"f1_micro\", refit=True, cv=5, verbose=3)\nsearch.fit(X_train_full, y_train_full)\nsearch.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final model\n\nlr_model = SGDClassifier(random_state=32,loss=\"log\",penalty=\"l1\",alpha=0.001,\n                         eta0=100,learning_rate=\"adaptive\")\nlr_model.fit(X_train, y_train)\nprint(classification_report(y_test, lr_model.predict(X_test)))\nprint(f1_score(y_test, lr_model.predict(X_test), average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-12-18T15:24:57.748294Z","iopub.execute_input":"2022-12-18T15:24:57.748688Z","iopub.status.idle":"2022-12-18T15:24:58.502215Z","shell.execute_reply.started":"2022-12-18T15:24:57.748655Z","shell.execute_reply":"2022-12-18T15:24:58.500884Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.55      0.31      0.40      1327\n           1       0.61      0.80      0.69      1768\n\n    accuracy                           0.59      3095\n   macro avg       0.58      0.56      0.55      3095\nweighted avg       0.58      0.59      0.57      3095\n\n0.5938610662358643\n","output_type":"stream"}]}]}